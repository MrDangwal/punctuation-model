{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The script endeavors to execute punctuation restoration on the textual content held within the 'Review' column of a CSV file. Subsequently, the processed text is appended to the 'Punctuated Review' column. Owing to certain inherent limitations within the employed model, any text that remains unprocessed by the initial approach undergoes further processing through the utilization of POS tagging techniques."
      ],
      "metadata": {
        "id": "1gd8pxPYlu5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model used for this is available at https://github.com/snakers4"
      ],
      "metadata": {
        "id": "uT3EZZKjlfzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUsD37PXj5Q0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import package\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "\n",
        "# Define function to correct punctuation and case of a review\n",
        "def correct_review(review):\n",
        "    # Tokenize the review into sentences\n",
        "    sentences = sent_tokenize(review)\n",
        "\n",
        "    # Apply POS tagging using TextBlob\n",
        "    tagged_words = []\n",
        "    for sentence in sentences:\n",
        "        blob = TextBlob(sentence)\n",
        "        tags = blob.tags  # Get the POS tags for each word in the sentence\n",
        "        tagged_words.extend([(word, pos) for word, pos in tags])\n",
        "\n",
        "    # Apply rules to add punctuation and correct case\n",
        "    corrected_words = []\n",
        "    for i, (word, pos) in enumerate(tagged_words):\n",
        "        # Add period at the end of the sentence\n",
        "        if i == len(tagged_words) - 1:\n",
        "            if pos in ['NN', 'NNS', 'NNP', 'NNPS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
        "                word += '.'\n",
        "            else:\n",
        "                word += '.'\n",
        "\n",
        "            # Handle multiple consecutive punctuation marks\n",
        "            word = re.sub(r'([.!?])\\1+', r'\\1', word)\n",
        "\n",
        "        # Add comma after adjectives or before coordinating conjunctions (e.g., and, but, or)\n",
        "        elif pos.startswith('JJ') or (pos == 'CC' and word != ','):\n",
        "            word += ','\n",
        "\n",
        "        # Capitalize the first word of the sentence\n",
        "        if i == 0:\n",
        "            word = word.capitalize()\n",
        "\n",
        "        # Add semicolon, closing parenthesis, or closing quotation mark if applicable\n",
        "        if word.endswith(';'):\n",
        "            word += ';'\n",
        "        elif word.startswith('(') and not word.endswith(')'):\n",
        "            word += ')'\n",
        "        elif word.startswith('“') and not word.endswith('”'):\n",
        "            word += '”'\n",
        "\n",
        "        # Handling quotes and apostrophes\n",
        "        if word.startswith(\"'\") and not word.endswith(\"'\"):\n",
        "            word += \"'\"\n",
        "        elif word.startswith('\"') and not word.endswith('\"'):\n",
        "            word += '\"'\n",
        "\n",
        "        corrected_words.append(word)\n",
        "\n",
        "    corrected_review = ' '.join(corrected_words)\n",
        "    return corrected_review\n",
        "\n",
        "# Load the data (assuming you have a DataFrame named 'data')\n",
        "data = pd.read_csv('Homedepot_Review data.csv')  # Update with your actual data source\n",
        "\n",
        "# Convert 'Review' column to lowercase\n",
        "data['Review'] = data['Review'].str.lower()\n",
        "\n",
        "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
        "                               'latest_silero_models.yml',\n",
        "                               progress=False)\n",
        "\n",
        "with open('latest_silero_models.yml', 'r') as yaml_file:\n",
        "    models = yaml.load(yaml_file, Loader=yaml.SafeLoader)\n",
        "model_conf = models.get('te_models').get('latest')\n",
        "\n",
        "model_url = model_conf.get('package')\n",
        "\n",
        "model_dir = \"downloaded_model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "model_path = os.path.join(model_dir, os.path.basename(model_url))\n",
        "\n",
        "if not os.path.isfile(model_path):\n",
        "    torch.hub.download_url_to_file(model_url,\n",
        "                                   model_path,\n",
        "                                   progress=True)\n",
        "\n",
        "imp = package.PackageImporter(model_path)\n",
        "model = imp.load_pickle(\"te_model\", \"model\")\n",
        "example_texts = model.examples\n",
        "\n",
        "def apply_te(text, lan='en'):\n",
        "    return model.enhance_text(text, lan)\n",
        "\n",
        "def process_row(row):\n",
        "    idx, review = row\n",
        "    try:\n",
        "        punctuated_review = apply_te(review, lan='en')\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {idx} with the model: {e}\")\n",
        "        # Use the provided function to process reviews with errors\n",
        "        punctuated_review = correct_review(review)\n",
        "    return idx, punctuated_review\n",
        "\n",
        "# Create a new column \"Punctuated Review\"\n",
        "data['Punctuated Review'] = ''\n",
        "\n",
        "# Define the number of processes to use\n",
        "num_processes = cpu_count()\n",
        "\n",
        "# Process and punctuate reviews using multiprocessing and tqdm\n",
        "with Pool(num_processes) as pool:\n",
        "    results = list(tqdm(pool.imap(process_row, data[['Review']].itertuples(index=True, name=None)),\n",
        "                        total=len(data), desc=\"Processing\"))\n",
        "\n",
        "# Update the DataFrame with the punctuated reviews\n",
        "for idx, punctuated_review in results:\n",
        "    data.at[idx, 'Punctuated Review'] = punctuated_review\n",
        "\n",
        "# Save the updated DataFrame with the punctuated reviews\n",
        "data.to_csv('processed_data.csv', index=False)  # Update with desired output file name\n"
      ]
    }
  ]
}